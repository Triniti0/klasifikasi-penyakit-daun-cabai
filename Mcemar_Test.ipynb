{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Triniti0/klasifikasi-penyakit-daun-cabai/blob/main/Mcemar_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# McNemar test untuk model baseline dan model dengan trade-off terbaik"
      ],
      "metadata": {
        "id": "SkKCyE8r9PdK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJRj2VbzrTQ4",
        "outputId": "451fc0ac-7f3b-4ded-b30b-262e9c138614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLnToThhrYMb",
        "outputId": "cafbc571-d4b0-4506-f42c-0eb4d9b8779a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "baseline_model = tf.keras.models.load_model(\n",
        "    \"/content/drive/MyDrive/Seminar Hasil/Experiments/Baseline/Baseline_Model.h5\"\n",
        ")\n",
        "\n",
        "best_model = tf.keras.models.load_model(\n",
        "    \"/content/drive/MyDrive/Seminar Hasil/Experiments/Partial_FineTuning/Best_Model_Partial_FineTuning_LR0.0001_OPTsgd_BS16_DR0.2_SCHstep.h5\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1J8apNNrnNY",
        "outputId": "3da83605-ddc5-4a18-9e89-9b0cb3506207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 620 files belonging to 8 classes.\n",
            "Class order: ['Anthracnose', 'Bacterial Spot', 'Cercospora Leaf Spot', 'Curl Virus', 'Healthy Leaf', 'Nutrition Deficiency', 'White spot', 'yellow disease']\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "TEST_PATH = \"/content/drive/MyDrive/Seminar Hasil/dataset_processed/test\"\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    TEST_PATH,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "class_names = test_ds.class_names\n",
        "print(\"Class order:\", class_names)\n",
        "\n",
        "def preprocess(x, y):\n",
        "    return preprocess_input(x), y\n",
        "\n",
        "test_ds = test_ds.map(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_loss, baseline_acc = baseline_model.evaluate(test_ds, verbose=0)\n",
        "best_loss, best_acc = best_model.evaluate(test_ds, verbose=0)\n",
        "\n",
        "print(\"Baseline Accuracy:\", baseline_acc)\n",
        "print(\"Optimized Accuracy:\", best_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rr2shzU9ENf",
        "outputId": "12cc2776-cbd3-44a4-e051-be67d1b8257f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 0.8725806474685669\n",
            "Optimized Accuracy: 0.9967741966247559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "y_pred_baseline = []\n",
        "y_pred_best = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    pred_base = baseline_model.predict(images, verbose=0)\n",
        "    pred_best = best_model.predict(images, verbose=0)\n",
        "\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred_baseline.extend(np.argmax(pred_base, axis=1))\n",
        "    y_pred_best.extend(np.argmax(pred_best, axis=1))\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred_baseline = np.array(y_pred_baseline)\n",
        "y_pred_best = np.array(y_pred_best)"
      ],
      "metadata": {
        "id": "t-VvDVwC9fKv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Manual Baseline Acc:\", np.mean(y_pred_baseline == y_true))\n",
        "print(\"Manual Optimized Acc:\", np.mean(y_pred_best == y_true))\n",
        "print(\"Total Samples:\", len(y_true))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmjsQ-Rt9joF",
        "outputId": "1a596384-2aaa-4da2-e4a3-466d12dc1f9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Baseline Acc: 0.8725806451612903\n",
            "Manual Optimized Acc: 0.9967741935483871\n",
            "Total Samples: 620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_correct = (y_pred_baseline == y_true)\n",
        "optimized_correct = (y_pred_best == y_true)\n",
        "\n",
        "n11 = np.sum(baseline_correct & optimized_correct)\n",
        "n00 = np.sum(~baseline_correct & ~optimized_correct)\n",
        "n01 = np.sum(~baseline_correct & optimized_correct)\n",
        "n10 = np.sum(baseline_correct & ~optimized_correct)\n",
        "\n",
        "print(\"\\nContingency Table:\")\n",
        "print(\"n11 (keduanya benar):\", n11)\n",
        "print(\"n00 (keduanya salah):\", n00)\n",
        "print(\"n01 (baseline salah, optimasi benar):\", n01)\n",
        "print(\"n10 (baseline benar, optimasi salah):\", n10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f69pqF8s9ndt",
        "outputId": "c939b6fe-7c17-4c3c-bc20-08d1f06c1dbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Contingency Table:\n",
            "n11 (keduanya benar): 540\n",
            "n00 (keduanya salah): 1\n",
            "n01 (baseline salah, optimasi benar): 78\n",
            "n10 (baseline benar, optimasi salah): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = [[n11, n01],\n",
        "         [n10, n00]]\n",
        "\n",
        "result = mcnemar(table, exact=False, correction=True)\n",
        "\n",
        "print(\"\\nMcNemar Statistic:\", result.statistic)\n",
        "print(\"p-value:\", result.pvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_fA7gGh9tSA",
        "outputId": "77f6046d-eb42-45eb-a18a-7e8915711b3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "McNemar Statistic: 73.11392405063292\n",
            "p-value: 1.2237811471935489e-17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05\n",
        "\n",
        "if result.pvalue < alpha:\n",
        "    print(\"\\nPerbedaan SIGNIFIKAN secara statistik (p < 0.05)\")\n",
        "else:\n",
        "    print(\"\\nTidak ada perbedaan signifikan secara statistik (p â‰¥ 0.05)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl_N2u2E9vmo",
        "outputId": "1bf1dc51-43ab-4364-9904-90e1575d2e4d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perbedaan SIGNIFIKAN secara statistik (p < 0.05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# McNemar test untuk semua model yang digunakan (McNemar Pairwise)"
      ],
      "metadata": {
        "id": "0kd_ZRMX-ABh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_feature = tf.keras.models.load_model(\"/content/drive/MyDrive/Seminar Hasil/Experiments/Feature_Extraction/best_LR0.001_OPTadam_BS32_DR0.3.h5\")\n",
        "model_partial = tf.keras.models.load_model(\"/content/drive/MyDrive/Seminar Hasil/Experiments/Partial_FineTuning/Best_Model_Partial_FineTuning_LR0.0001_OPTsgd_BS16_DR0.2_SCHstep.h5\")\n",
        "model_progressive = tf.keras.models.load_model(\"/content/drive/MyDrive/Seminar Hasil/Experiments/Progressive_FineTuning/Best_Model_Progressive_FineTuning_EPOCHS20.h5\")\n",
        "model_two_stage = tf.keras.models.load_model(\"/content/drive/MyDrive/Seminar Hasil/Experiments/Two_Stage_Training/Best_Model_Two_Stage_Training.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEbRBjWG-EaU",
        "outputId": "1b49c89c-6c74-49ad-8fad-e51be655eed2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "\n",
        "pred_feature = []\n",
        "pred_partial = []\n",
        "pred_progressive = []\n",
        "pred_two_stage = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    y_true.extend(labels.numpy())\n",
        "\n",
        "    pred_feature.extend(np.argmax(model_feature.predict(images, verbose=0), axis=1))\n",
        "    pred_partial.extend(np.argmax(model_partial.predict(images, verbose=0), axis=1))\n",
        "    pred_progressive.extend(np.argmax(model_progressive.predict(images, verbose=0), axis=1))\n",
        "    pred_two_stage.extend(np.argmax(model_two_stage.predict(images, verbose=0), axis=1))\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "pred_feature = np.array(pred_feature)\n",
        "pred_partial = np.array(pred_partial)\n",
        "pred_progressive = np.array(pred_progressive)\n",
        "pred_two_stage = np.array(pred_two_stage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnguI_hW-MSq",
        "outputId": "a58a0280-3bb0-409a-8049-ad0f708858e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 41 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7933233b9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 42 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7933233baac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "def mcnemar_test(pred1, pred2, y_true, name1, name2):\n",
        "\n",
        "    correct1 = (pred1 == y_true)\n",
        "    correct2 = (pred2 == y_true)\n",
        "\n",
        "    n01 = np.sum(~correct1 & correct2)\n",
        "    n10 = np.sum(correct1 & ~correct2)\n",
        "\n",
        "    table = [[0, n01],\n",
        "             [n10, 0]]\n",
        "\n",
        "    result = mcnemar(table, exact=False, correction=True)\n",
        "\n",
        "    print(f\"\\n{name1} vs {name2}\")\n",
        "    print(\"n01:\", n01)\n",
        "    print(\"n10:\", n10)\n",
        "    print(\"p-value:\", result.pvalue)\n",
        "\n",
        "    return result.pvalue"
      ],
      "metadata": {
        "id": "AT4BOiqO-SPN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_values = []\n",
        "\n",
        "p_values.append(mcnemar_test(pred_partial, pred_progressive, y_true, \"Partial\", \"Progressive\"))\n",
        "p_values.append(mcnemar_test(pred_partial, pred_feature, y_true, \"Partial\", \"Feature\"))\n",
        "p_values.append(mcnemar_test(pred_partial, pred_two_stage, y_true, \"Partial\", \"Two-Stage\"))\n",
        "p_values.append(mcnemar_test(pred_progressive, pred_feature, y_true, \"Progressive\", \"Feature\"))\n",
        "p_values.append(mcnemar_test(pred_progressive, pred_two_stage, y_true, \"Progressive\", \"Two-Stage\"))\n",
        "p_values.append(mcnemar_test(pred_feature, pred_two_stage, y_true, \"Feature\", \"Two-Stage\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRQ8Crux-U_R",
        "outputId": "76d0c089-7a80-4dc9-bcba-2c67673923c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Partial vs Progressive\n",
            "n01: 0\n",
            "n10: 1\n",
            "p-value: 1.0\n",
            "\n",
            "Partial vs Feature\n",
            "n01: 0\n",
            "n10: 4\n",
            "p-value: 0.13361440253771584\n",
            "\n",
            "Partial vs Two-Stage\n",
            "n01: 0\n",
            "n10: 4\n",
            "p-value: 0.13361440253771584\n",
            "\n",
            "Progressive vs Feature\n",
            "n01: 0\n",
            "n10: 3\n",
            "p-value: 0.24821307898992026\n",
            "\n",
            "Progressive vs Two-Stage\n",
            "n01: 1\n",
            "n10: 4\n",
            "p-value: 0.37109336952269756\n",
            "\n",
            "Feature vs Two-Stage\n",
            "n01: 3\n",
            "n10: 3\n",
            "p-value: 0.6830913983096086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bonferonni correction\n",
        "alpha = 0.05\n",
        "bonf_alpha = alpha / 6\n",
        "\n",
        "print(\"\\nBonferroni corrected alpha:\", bonf_alpha)\n",
        "\n",
        "for i, p in enumerate(p_values):\n",
        "    if p < bonf_alpha:\n",
        "        print(f\"Comparison {i+1} SIGNIFICANT\")\n",
        "    else:\n",
        "        print(f\"Comparison {i+1} NOT significant\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_XfwkPL-Z1-",
        "outputId": "1f859bd8-4e55-4d0e-d27b-21777c852e38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bonferroni corrected alpha: 0.008333333333333333\n",
            "Comparison 1 NOT significant\n",
            "Comparison 2 NOT significant\n",
            "Comparison 3 NOT significant\n",
            "Comparison 4 NOT significant\n",
            "Comparison 5 NOT significant\n",
            "Comparison 6 NOT significant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#menghitung effect size antar model\n",
        "def pairwise_effect_size(pred1, pred2, y_true, name1, name2):\n",
        "\n",
        "    correct1 = (pred1 == y_true)\n",
        "    correct2 = (pred2 == y_true)\n",
        "\n",
        "    n01 = np.sum(~correct1 & correct2)\n",
        "    n10 = np.sum(correct1 & ~correct2)\n",
        "    N = len(y_true)\n",
        "\n",
        "    # Odds Ratio\n",
        "    if n10 == 0:\n",
        "        odds_ratio = np.inf\n",
        "    else:\n",
        "        odds_ratio = n01 / n10\n",
        "\n",
        "    # Cohen's g\n",
        "    cohens_g = (n01 - n10) / N\n",
        "\n",
        "    print(f\"\\nEffect Size: {name1} vs {name2}\")\n",
        "    print(\"n01:\", n01)\n",
        "    print(\"n10:\", n10)\n",
        "    print(\"Odds Ratio:\", odds_ratio)\n",
        "    print(\"Cohen's g:\", cohens_g)\n",
        "\n",
        "    return odds_ratio, cohens_g"
      ],
      "metadata": {
        "id": "8yf3NIcW-f9O"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairwise_effect_size(pred_partial, pred_progressive, y_true, \"Partial\", \"Progressive\")\n",
        "pairwise_effect_size(pred_partial, pred_feature, y_true, \"Partial\", \"Feature\")\n",
        "pairwise_effect_size(pred_partial, pred_two_stage, y_true, \"Partial\", \"Two-Stage\")\n",
        "pairwise_effect_size(pred_progressive, pred_feature, y_true, \"Progressive\", \"Feature\")\n",
        "pairwise_effect_size(pred_progressive, pred_two_stage, y_true, \"Progressive\", \"Two-Stage\")\n",
        "pairwise_effect_size(pred_feature, pred_two_stage, y_true, \"Feature\", \"Two-Stage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR_9mSI6-lgK",
        "outputId": "75aa957d-e2f0-4c9d-9f79-fbffceb78e78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Effect Size: Partial vs Progressive\n",
            "n01: 0\n",
            "n10: 1\n",
            "Odds Ratio: 0.0\n",
            "Cohen's g: -0.0016129032258064516\n",
            "\n",
            "Effect Size: Partial vs Feature\n",
            "n01: 0\n",
            "n10: 4\n",
            "Odds Ratio: 0.0\n",
            "Cohen's g: -0.0064516129032258064\n",
            "\n",
            "Effect Size: Partial vs Two-Stage\n",
            "n01: 0\n",
            "n10: 4\n",
            "Odds Ratio: 0.0\n",
            "Cohen's g: -0.0064516129032258064\n",
            "\n",
            "Effect Size: Progressive vs Feature\n",
            "n01: 0\n",
            "n10: 3\n",
            "Odds Ratio: 0.0\n",
            "Cohen's g: -0.004838709677419355\n",
            "\n",
            "Effect Size: Progressive vs Two-Stage\n",
            "n01: 1\n",
            "n10: 4\n",
            "Odds Ratio: 0.25\n",
            "Cohen's g: -0.004838709677419355\n",
            "\n",
            "Effect Size: Feature vs Two-Stage\n",
            "n01: 3\n",
            "n10: 3\n",
            "Odds Ratio: 1.0\n",
            "Cohen's g: 0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(1.0), np.float64(0.0))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPif4+WKZN8yLPcIuzTWvXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}